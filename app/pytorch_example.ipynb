{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "torch.set_printoptions(linewidth=120)\n",
    "torch.set_grad_enabled(True)\n",
    "\n",
    "import torch.cuda as t\n",
    "import cupy as cu\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import tensorboard\n",
    "\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch v1.9.0\n",
      "Torchvision v0.10.0\n",
      "Tensorboard v2.4.0\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch v\"+torch.__version__)\n",
    "print(\"Torchvision v\"+torchvision.__version__)\n",
    "print(\"Tensorboard v\"+tensorboard.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce RTX 2080 Ti\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is avail\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "# Support both CPU and GPU, when avail\n",
    "\n",
    "if torch.cuda.is_available():  \n",
    "  dev = \"cuda:0\" \n",
    "  cu = cu\n",
    "else:  \n",
    "  dev = \"cpu\"  \n",
    "  cu = np\n",
    "\n",
    "device = torch.device(dev)\n",
    "\n",
    "# Utility function to interchangbly support CPU and GPU when avail\n",
    "def gpu(t):\n",
    "    return t.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], device='cuda:0')\n",
      "torch.float32\n",
      "cpu\n",
      "torch.strided\n"
     ]
    }
   ],
   "source": [
    "gpu_cpu_test = gpu(torch.zeros(4,3))\n",
    "print(gpu_cpu_test)\n",
    "\n",
    "# Not piped to gpu\n",
    "t = torch.Tensor()\n",
    "\n",
    "# uniform number type for tensor\n",
    "print(t.dtype)\n",
    "\n",
    "# gpu or cpu?\n",
    "print(t.device)\n",
    "\n",
    "# Strided is default for how tensors are laid out in mem\n",
    "print(t.layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6., 0., 0., 0., 0., 0.], device='cuda:0', dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "# NVIDIA GPU Computing Tips with code example: \n",
    "When working with #cupy and #pytorch, you might have to do a \n",
    "couple things diff to turn a #numpy / cupy array into a tensor. \n",
    "First you need to copy the numpy (cupy )array, this will \n",
    "allocate new memory for numpy array . This is to prevent  \n",
    "negative strides within Ndarray which are  the number of \n",
    "locations in memory between beginnings of successive array elements. \n",
    "Next, we flip it with the Axis in the array, which  \n",
    "tells which entries are reversed. \n",
    "Lastly, we can finally convert the copied array to a tensor. \n",
    "dtypes are data type enforcement and cuda:0 is piping data to the \n",
    "GPU device which has an index of 0. This provides 7-9x speed up on \n",
    "processing in most scenarios for computer vision, and 20x speed up \n",
    "for analytics/non-machine vision applications like NLP. \n",
    "The following solution performs near 100% of the \n",
    "operations on the GPU:\n",
    "'''\n",
    "\n",
    "cupy_gpu = torch.tensor(\n",
    "    cu.flip(cu.copy(\n",
    "        cu.array([1,2,3,4,5,6])),\n",
    "            axis=0),\n",
    "            dtype=torch.float16, \n",
    "            device=dev\n",
    ")\n",
    "\n",
    "print(cupy_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3  4]\n",
      " [ 5  6  7  8  9]\n",
      " [10 11 12 13 14]]\n"
     ]
    }
   ],
   "source": [
    "# CPU Bound Op\n",
    "numpy_cpu = np.arange(15).reshape(3, 5)\n",
    "print(numpy_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Start the example using Torch+Tensorboard\n",
    "\n",
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=12 * 4 * 4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "        \n",
    "    def forward(self, t):\n",
    "       \n",
    "        t = F.relu(self.conv1(t))\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        t = F.relu(self.conv2(t))\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        t = t.flatten(start_dim=1)\n",
    "        t = F.relu(self.fc1(t))\n",
    "        \n",
    "        t = F.relu(self.fc2(t))\n",
    "        \n",
    "        t = self.out(t)\n",
    "        \n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bd454637c6349fea1f956e26ca00d4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26421880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57ec5a74ea4148b2b9dbb81533ef6fec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bbf0bfec6134d8f968a71fcd02f2672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4422102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "050d0c6b5dc84e878d26cf6a8d1585cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448255797/work/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root='./data'\n",
    "    ,train=True\n",
    "    ,download=True\n",
    "    ,transform=transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Starting out with TensorBoard (Network Graph and Images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448255797/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "tb = SummaryWriter()\n",
    "\n",
    "network = Network()\n",
    "images, labels = next(iter(train_loader))\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "tb.add_image('images', grid)\n",
    "tb.add_graph(network, images)\n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training Loop Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 total_correct: 47124 loss: 342.5143479704857\n"
     ]
    }
   ],
   "source": [
    "network = Network()\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=100, shuffle=True)\n",
    "optimizer = optim.Adam(network.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(1):\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    \n",
    "    for batch in train_loader: # Get Batch\n",
    "        images, labels = batch \n",
    "        \n",
    "        preds = network(images) # Pass Batch\n",
    "        loss = F.cross_entropy(preds, labels) # Calculate Loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() # Calculate Gradients\n",
    "        optimizer.step() # Update Weights\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_correct += get_num_correct(preds, labels)\n",
    "\n",
    "    print(\"epoch\", epoch, \"total_correct:\", total_correct, \"loss:\", total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop with Tensorboard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 total_correct: 47551 loss: 329.9411251246929\n",
      "epoch 1 total_correct: 51709 loss: 224.40080043673515\n",
      "epoch 2 total_correct: 52501 loss: 204.56086319684982\n",
      "epoch 3 total_correct: 52866 loss: 193.04770627617836\n",
      "epoch 4 total_correct: 52924 loss: 191.4370125681162\n",
      "epoch 5 total_correct: 53228 loss: 187.44795136898756\n",
      "epoch 6 total_correct: 53372 loss: 180.5123216882348\n",
      "epoch 7 total_correct: 53406 loss: 179.26758498698473\n",
      "epoch 8 total_correct: 53441 loss: 178.64229875802994\n",
      "epoch 9 total_correct: 53312 loss: 180.6327881887555\n"
     ]
    }
   ],
   "source": [
    "network = Network()\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=100, shuffle=True)\n",
    "optimizer = optim.Adam(network.parameters(), lr=0.01)\n",
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "tb = SummaryWriter()\n",
    "tb.add_image('images', grid)\n",
    "tb.add_graph(network, images)\n",
    "\n",
    "for epoch in range(10):\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    \n",
    "    for batch in train_loader: # Get Batch\n",
    "        images, labels = batch \n",
    "\n",
    "        preds = network(images) # Pass Batch\n",
    "        loss = F.cross_entropy(preds, labels) # Calculate Loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() # Calculate Gradients\n",
    "        optimizer.step() # Update Weights\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_correct += get_num_correct(preds, labels)\n",
    "    \n",
    "    tb.add_scalar('Loss', total_loss, epoch)\n",
    "    tb.add_scalar('Number Correct', total_correct, epoch)\n",
    "    tb.add_scalar('Accuracy', total_correct / len(train_set), epoch)\n",
    "    \n",
    "    tb.add_histogram('conv1.bias', network.conv1.bias, epoch)\n",
    "    tb.add_histogram('conv1.weight', network.conv1.weight, epoch)\n",
    "    tb.add_histogram('conv1.weight.grad', network.conv1.weight.grad, epoch)\n",
    "    \n",
    "    print(\"epoch\", epoch, \"total_correct:\", total_correct, \"loss:\", total_loss)\n",
    "    \n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CNN Training Hyperparamters - Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 total_correct: 47264 loss: 337.4169496446848\n",
      "epoch 1 total_correct: 51555 loss: 231.8068321943283\n",
      "epoch 2 total_correct: 52183 loss: 212.24386222660542\n",
      "epoch 3 total_correct: 52453 loss: 203.61098565161228\n",
      "epoch 4 total_correct: 52838 loss: 194.67393566668034\n"
     ]
    }
   ],
   "source": [
    "network = Network()\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=100, shuffle=True)\n",
    "optimizer = optim.Adam(network.parameters(), lr=0.01)\n",
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "tb = SummaryWriter()\n",
    "tb.add_image('images', grid)\n",
    "tb.add_graph(network, images)\n",
    "\n",
    "for epoch in range(5):\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    \n",
    "    for batch in train_loader: # Get Batch\n",
    "        images, labels = batch \n",
    "\n",
    "        preds = network(images) # Pass Batch\n",
    "        loss = F.cross_entropy(preds, labels) # Calculate Loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() # Calculate Gradients\n",
    "        optimizer.step() # Update Weights\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_correct += get_num_correct(preds, labels)\n",
    "    \n",
    "    tb.add_scalar('Loss', total_loss, epoch)\n",
    "    tb.add_scalar('Number Correct', total_correct, epoch)\n",
    "    tb.add_scalar('Accuracy', total_correct / len(train_set), epoch)\n",
    "    \n",
    "    #tb.add_histogram('conv1.bias', network.conv1.bias, epoch)\n",
    "    #tb.add_histogram('conv1.weight', network.conv1.weight, epoch)\n",
    "    #tb.add_histogram('conv1.weight.grad', network.conv1.weight.grad, epoch)\n",
    "    \n",
    "    for name, weight in network.named_parameters():\n",
    "        tb.add_histogram(name, weight, epoch)\n",
    "        tb.add_histogram(f'{name}.grad', weight.grad, epoch)\n",
    "    \n",
    "    print(\"epoch\", epoch, \"total_correct:\", total_correct, \"loss:\", total_loss)\n",
    "    \n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight torch.Size([6, 1, 5, 5])\n",
      "conv1.bias torch.Size([6])\n",
      "conv2.weight torch.Size([12, 6, 5, 5])\n",
      "conv2.bias torch.Size([12])\n",
      "fc1.weight torch.Size([120, 192])\n",
      "fc1.bias torch.Size([120])\n",
      "fc2.weight torch.Size([60, 120])\n",
      "fc2.bias torch.Size([60])\n",
      "out.weight torch.Size([10, 60])\n",
      "out.bias torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name, weight in network.named_parameters():\n",
    "    print(name, weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight.grad torch.Size([6, 1, 5, 5])\n",
      "conv1.bias.grad torch.Size([6])\n",
      "conv2.weight.grad torch.Size([12, 6, 5, 5])\n",
      "conv2.bias.grad torch.Size([12])\n",
      "fc1.weight.grad torch.Size([120, 192])\n",
      "fc1.bias.grad torch.Size([120])\n",
      "fc2.weight.grad torch.Size([60, 120])\n",
      "fc2.bias.grad torch.Size([60])\n",
      "out.weight.grad torch.Size([10, 60])\n",
      "out.bias.grad torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name, weight in network.named_parameters():\n",
    "    print(f'{name}.grad', weight.grad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Paramterized Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 total_correct: 46122 loss: 36384.994104504585\n",
      "epoch 1 total_correct: 50953 loss: 24450.16450881958\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "lr = 0.01\n",
    "\n",
    "network = Network()\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\n",
    "optimizer = optim.Adam(network.parameters(), lr=lr)\n",
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "comment = f' batch_size={batch_size} lr={lr}'\n",
    "tb = SummaryWriter(comment=comment)\n",
    "tb.add_image('images', grid)\n",
    "tb.add_graph(network, images)\n",
    "\n",
    "for epoch in range(2):\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    for batch in train_loader:\n",
    "        images, labels = batch # Get Batch\n",
    "        preds = network(images) # Pass Batch\n",
    "        loss = F.cross_entropy(preds, labels) # Calculate Loss\n",
    "        optimizer.zero_grad() # Zero Gradients\n",
    "        loss.backward() # Calculate Gradients\n",
    "        optimizer.step() # Update Weights\n",
    "\n",
    "        total_loss += loss.item() * batch_size\n",
    "        total_correct += get_num_correct(preds, labels)\n",
    "    \n",
    "    tb.add_scalar('Loss', total_loss, epoch)\n",
    "    tb.add_scalar('Number Correct', total_correct, epoch)\n",
    "    tb.add_scalar('Accuracy', total_correct / len(train_set), epoch)\n",
    "    \n",
    "    for name, param in network.named_parameters():\n",
    "        tb.add_histogram(name, param, epoch)\n",
    "        tb.add_histogram(f'{name}.grad', param.grad, epoch)\n",
    "    \n",
    "    print(\"epoch\", epoch, \"total_correct:\", total_correct, \"loss:\", total_loss)  \n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 total_correct: 46806 loss: 35112.37597465515\n",
      "epoch 0 total_correct: 41893 loss: 47429.14132773876\n",
      "epoch 0 total_correct: 32811 loss: 80122.57377505302\n",
      "epoch 0 total_correct: 7595 loss: 137384.78164672852\n",
      "epoch 0 total_correct: 39205 loss: 54641.52693748474\n",
      "epoch 0 total_correct: 30477 loss: 91507.25823640823\n",
      "epoch 0 total_correct: 9390 loss: 137259.95635986328\n",
      "epoch 0 total_correct: 6146 loss: 138244.85564231873\n",
      "epoch 0 total_correct: 13004 loss: 130699.30791854858\n",
      "epoch 0 total_correct: 7904 loss: 137979.51936721802\n",
      "epoch 0 total_correct: 6057 loss: 138276.40771865845\n",
      "epoch 0 total_correct: 6050 loss: 138321.31147384644\n"
     ]
    }
   ],
   "source": [
    "batch_size_list = [100, 1000, 10000]\n",
    "lr_list = [.01, .001, .0001, .00001]\n",
    "\n",
    "for batch_size in batch_size_list:\n",
    "    for lr in lr_list:\n",
    "        network = Network()\n",
    "        train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\n",
    "        optimizer = optim.Adam(network.parameters(), lr=lr)\n",
    "\n",
    "        images, labels = next(iter(train_loader))\n",
    "        grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "        comment=f' batch_size={batch_size} lr={lr}'\n",
    "        tb = SummaryWriter(comment=comment)\n",
    "        tb.add_image('images', grid)\n",
    "        tb.add_graph(network, images)\n",
    "\n",
    "        for epoch in range(1):\n",
    "            total_loss = 0\n",
    "            total_correct = 0\n",
    "            for batch in train_loader:\n",
    "                images, labels = batch # Get Batch\n",
    "                preds = network(images) # Pass Batch\n",
    "                loss = F.cross_entropy(preds, labels) # Calculate Loss\n",
    "                optimizer.zero_grad() # Zero Gradients\n",
    "                loss.backward() # Calculate Gradients\n",
    "                optimizer.step() # Update Weights\n",
    "\n",
    "                total_loss += loss.item() * batch_size\n",
    "                total_correct += get_num_correct(preds, labels)\n",
    "\n",
    "            tb.add_scalar('Loss', total_loss, epoch)\n",
    "            tb.add_scalar('Number Correct', total_correct, epoch)\n",
    "            tb.add_scalar('Accuracy', total_correct / len(train_set), epoch)\n",
    "\n",
    "            for name, param in network.named_parameters():\n",
    "                tb.add_histogram(name, param, epoch)\n",
    "                tb.add_histogram(f'{name}.grad', param.grad, epoch)\n",
    "\n",
    "            print(\"epoch\", epoch, \"total_correct:\", total_correct, \"loss:\", total_loss)  \n",
    "        tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = dict(\n",
    "    lr = [.01, .001]\n",
    "    ,batch_size = [10, 100, 1000]\n",
    "    ,shuffle = [True, False]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.01, 0.001], [10, 100, 1000], [True, False]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_values = [v for v in parameters.values()]\n",
    "param_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 10 True\n",
      "0.01 10 False\n",
      "0.01 100 True\n",
      "0.01 100 False\n",
      "0.01 1000 True\n",
      "0.01 1000 False\n",
      "0.001 10 True\n",
      "0.001 10 False\n",
      "0.001 100 True\n",
      "0.001 100 False\n",
      "0.001 1000 True\n",
      "0.001 1000 False\n"
     ]
    }
   ],
   "source": [
    "for lr, batch_size, shuffle in product(*param_values): \n",
    "    print (lr, batch_size, shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 total_correct: 46106 loss: 36976.01890651742\n",
      "epoch 1 total_correct: 48232 loss: 32253.95067493315\n",
      "epoch 2 total_correct: 48629 loss: 31062.413288153766\n",
      "epoch 3 total_correct: 48735 loss: 31493.25378237292\n",
      "epoch 4 total_correct: 48902 loss: 31069.599554706365\n",
      "epoch 5 total_correct: 48856 loss: 31361.52362899622\n",
      "epoch 6 total_correct: 49162 loss: 30502.29696228774\n",
      "epoch 7 total_correct: 49308 loss: 31002.20635057427\n",
      "epoch 8 total_correct: 49323 loss: 30967.16022528708\n",
      "epoch 9 total_correct: 49470 loss: 30315.25373094715\n",
      "epoch 10 total_correct: 49339 loss: 30997.397101920797\n",
      "epoch 11 total_correct: 48822 loss: 32337.963016331196\n"
     ]
    }
   ],
   "source": [
    "for lr, batch_size, shuffle in product(*param_values): \n",
    "    comment = f' batch_size={batch_size} lr={lr} shuffle={shuffle}'\n",
    "    network = Network()\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=shuffle)\n",
    "    optimizer = optim.Adam(network.parameters(), lr=lr)\n",
    "    images, labels = next(iter(train_loader))\n",
    "    grid = torchvision.utils.make_grid(images)\n",
    "    tb = SummaryWriter(comment=comment)\n",
    "    tb.add_image('images', grid)\n",
    "    tb.add_graph(network, images)\n",
    "    for epoch in range(25):\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "        for batch in train_loader:\n",
    "            images, labels = batch # Get Batch\n",
    "            preds = network(images) # Pass Batch\n",
    "            loss = F.cross_entropy(preds, labels) # Calculate Loss\n",
    "            optimizer.zero_grad() # Zero Gradients\n",
    "            loss.backward() # Calculate Gradients\n",
    "            optimizer.step() # Update Weights\n",
    "\n",
    "            total_loss += loss.item() * batch_size\n",
    "            total_correct += get_num_correct(preds, labels)\n",
    "\n",
    "        tb.add_scalar('Loss', total_loss, epoch)\n",
    "        tb.add_scalar('Number Correct', total_correct, epoch)\n",
    "        tb.add_scalar('Accuracy', total_correct / len(train_set), epoch)\n",
    "\n",
    "        for name, param in network.named_parameters():\n",
    "            tb.add_histogram(name, param, epoch)\n",
    "            tb.add_histogram(f'{name}.grad', param.grad, epoch)\n",
    "\n",
    "        print(\"epoch\", epoch, \"total_correct:\", total_correct, \"loss:\", total_loss)  \n",
    "    tb.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
